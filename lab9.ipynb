{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "xi5fnKCC4HZB",
        "outputId": "30bb369c-39a4-40a7-e6d2-8b490791edd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'weather-dataset-rattle-package' dataset.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PySparkRuntimeError",
          "evalue": "[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPySparkRuntimeError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2972368407.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Stop any existing Spark session before creating a new one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lab9\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.driver.memory\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"4g\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    495\u001b[0m                         \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                     \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m                     \u001b[0;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m                     \u001b[0;31m# by all sessions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    199\u001b[0m             )\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             self._do_init(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 raise PySparkRuntimeError(\n\u001b[0m\u001b[1;32m    108\u001b[0m                     \u001b[0merror_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"JAVA_GATEWAY_EXITED\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mmessage_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPySparkRuntimeError\u001b[0m: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number."
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession, functions as F\n",
        "from pyspark.sql.functions import col, when\n",
        "import kagglehub, glob, os, shutil\n",
        "\n",
        "path = kagglehub.dataset_download(\"jsphyg/weather-dataset-rattle-package\")\n",
        "csv_path = f\"{path}/weatherAUS.csv\"\n",
        "\n",
        "# Stop any existing Spark session before creating a new one\n",
        "spark = SparkSession.builder.appName(\"lab9\").config(\"spark.driver.memory\", \"4g\").getOrCreate()\n",
        "\n",
        "df = spark.read.csv(csv_path, header=True, inferSchema=False)\n",
        "\n",
        "for c in df.columns:\n",
        "    df = df.withColumn(c, when((col(c).isin(\"NA\", \"NaN\", \"\", \"None\")), None).otherwise(col(c)))\n",
        "\n",
        "num_cols = [\n",
        "    \"MinTemp\", \"MaxTemp\", \"Rainfall\", \"Evaporation\", \"Sunshine\",\n",
        "    \"WindGustSpeed\", \"WindSpeed9am\", \"WindSpeed3pm\",\n",
        "    \"Humidity9am\", \"Humidity3pm\", \"Pressure9am\", \"Pressure3pm\",\n",
        "    \"Cloud9am\", \"Cloud3pm\", \"Temp9am\", \"Temp3pm\"\n",
        "]\n",
        "for c in num_cols:\n",
        "    df = df.withColumn(c, col(c).cast(\"float\"))\n",
        "\n",
        "df = df.filter(col(\"RainTomorrow\").isNotNull())\n",
        "\n",
        "for c in num_cols:\n",
        "    median = df.approxQuantile(c, [0.5], 0.01)[0]\n",
        "    df = df.na.fill({c: median})\n",
        "\n",
        "cat_cols = [c for c, t in df.dtypes if t == \"string\" and c not in [\"RainTomorrow\", \"Date\"]]\n",
        "for c in cat_cols:\n",
        "    mode = df.groupBy(c).count().orderBy(F.desc(\"count\")).first()[0]\n",
        "    df = df.na.fill({c: mode})\n",
        "\n",
        "df.show(5)\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g2s5Lkg-YUr",
        "outputId": "a0997ef7-8e25-420c-b60e-e844a5edd692"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for c in [\"Temp3pm\", \"Humidity3pm\", \"Rainfall\"]:\n",
        "    df = df.withColumn(c, col(c).cast(\"float\"))\n",
        "\n",
        "df.select(\"Date\", \"Location\", \"Temp3pm\").show(5)\n",
        "\n",
        "print(\"температура в 3PM > 30°C\")\n",
        "df.filter(col(\"Temp3pm\") > 30).show(5)\n",
        "\n",
        "print(\"сортировка по Temp3pm по убыванию\")\n",
        "df.orderBy(col(\"Temp3pm\").desc()).show(5)\n",
        "\n",
        "df.describe([\"Temp3pm\", \"Humidity3pm\", \"Rainfall\"]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MEZP_hD50Ww",
        "outputId": "81f6314d-93d6-4881-da1b-8b25d8bff1f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+-------+\n",
            "|      Date|Location|Temp3pm|\n",
            "+----------+--------+-------+\n",
            "|2008-12-01|  Albury|   21.8|\n",
            "|2008-12-02|  Albury|   24.3|\n",
            "|2008-12-03|  Albury|   23.2|\n",
            "|2008-12-04|  Albury|   26.5|\n",
            "|2008-12-05|  Albury|   29.7|\n",
            "+----------+--------+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "температура в 3PM > 30°C\n",
            "+----------+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
            "|      Date|Location|MinTemp|MaxTemp|Rainfall|Evaporation|Sunshine|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|Cloud9am|Cloud3pm|Temp9am|Temp3pm|RainToday|RainTomorrow|\n",
            "+----------+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
            "|2008-12-09|  Albury|    9.7|   31.9|     0.0|        4.6|     8.4|        NNW|         80.0|        SE|        NW|         7.0|        28.0|       42.0|        9.0|     1008.9|     1003.6|     5.0|     5.0|   18.3|   30.2|       No|         Yes|\n",
            "|2008-12-22|  Albury|   17.1|   33.0|     0.0|        4.6|     8.4|         NE|         43.0|        NE|         N|        17.0|        22.0|       38.0|       28.0|     1013.6|     1008.1|     5.0|     1.0|   24.5|   31.6|       No|          No|\n",
            "|2008-12-23|  Albury|   20.5|   31.8|     0.0|        4.6|     8.4|        WNW|         41.0|         W|         W|        19.0|        20.0|       54.0|       24.0|     1007.8|     1005.7|     5.0|     5.0|   23.8|   30.8|       No|          No|\n",
            "|2008-12-25|  Albury|   12.6|   32.4|     0.0|        4.6|     8.4|          W|         43.0|         E|         W|         4.0|        19.0|       49.0|       17.0|     1012.9|     1010.1|     5.0|     5.0|   21.5|   31.2|       No|          No|\n",
            "|2008-12-26|  Albury|   16.2|   33.9|     0.0|        4.6|     8.4|        WSW|         35.0|        SE|       WSW|         9.0|        13.0|       45.0|       19.0|     1010.9|     1007.6|     5.0|     1.0|   23.2|   33.0|       No|          No|\n",
            "+----------+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "сортировка по Temp3pm по убыванию\n",
            "+----------+----------------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
            "|      Date|        Location|MinTemp|MaxTemp|Rainfall|Evaporation|Sunshine|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|Cloud9am|Cloud3pm|Temp9am|Temp3pm|RainToday|RainTomorrow|\n",
            "+----------+----------------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
            "|2017-02-12|           Moree|   27.8|   47.3|     0.0|        4.6|     8.4|        SSW|         67.0|       NNE|        NW|        13.0|        28.0|       30.0|       10.0|     1003.9|      998.1|     7.0|     1.0|   32.9|   46.7|       No|          No|\n",
            "|2017-02-11|         Penrith|   23.3|   46.9|     0.0|        4.6|     8.4|          W|         50.0|         N|       WNW|         7.0|        30.0|       85.0|       14.0|     1017.6|     1015.2|     5.0|     5.0|   25.3|   46.2|       No|          No|\n",
            "|2011-01-25|         Woomera|   25.1|   48.1|     0.0|       22.4|    12.8|        WSW|         85.0|       NNE|        NW|        37.0|        43.0|       21.0|        7.0|     1003.4|     1000.4|     3.0|     2.0|   33.2|   46.1|       No|          No|\n",
            "|2009-02-07|MelbourneAirport|   18.8|   46.8|     0.0|       10.8|     8.5|         SW|         83.0|         N|        NW|        54.0|        39.0|       21.0|       10.0|     1003.1|      998.8|     2.0|     1.0|   32.7|   46.1|       No|         Yes|\n",
            "|2009-02-07|         Mildura|   26.1|   46.7|     0.0|       13.2|    11.7|        NNW|         56.0|       NNE|        NW|        24.0|        31.0|       11.0|       10.0|     1004.4|     1002.9|     0.0|     2.0|   36.4|   46.1|       No|          No|\n",
            "+----------+----------------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-------+------------------+------------------+------------------+\n",
            "|summary|           Temp3pm|       Humidity3pm|          Rainfall|\n",
            "+-------+------------------+------------------+------------------+\n",
            "|  count|            142193|            142193|            142193|\n",
            "|   mean|21.674059903435328|51.495741703178076|2.3267376041085477|\n",
            "| stddev| 6.871417079943964|20.532226778894465|  8.42642567656327|\n",
            "|    min|              -5.4|               0.0|               0.0|\n",
            "|    max|              46.7|             100.0|             371.0|\n",
            "+-------+------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files;\n",
        "output_path = \"output/lab9\"\n",
        "df.filter(col(\"Temp3pm\") > 30).write.csv(output_path, header=True, mode=\"overwrite\")\n",
        "\n",
        "final_file = f\"{output_path}.csv\"\n",
        "parts = sorted(glob.glob(f\"{output_path}/part-*.csv\"))\n",
        "with open(final_file, \"w\", encoding=\"utf-8\") as out:\n",
        "    for i, f in enumerate(parts):\n",
        "        lines = open(f, encoding=\"utf-8\").readlines()\n",
        "        out.writelines(lines if i == 0 else lines[1:])\n",
        "try:\n",
        "    files.download(final_file)\n",
        "except: pass\n",
        "\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hGYCfvNU7feA",
        "outputId": "7cd54729-dfbc-42fb-dcb0-95e3d06659bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2a897212-08b1-499c-8f10-74cb604f131f\", \"lab9.csv\", 2086790)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}